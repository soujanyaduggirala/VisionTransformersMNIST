{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN4FNclnNR_h",
        "outputId": "c4fa3299-c07a-45cc-9fbb-145cd05ca980"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 16.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pJ-kTxyCo85g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import sympy\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Needed toolboxes\n",
        "from tensorflow.keras import models, layers, callbacks\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers.core import Activation\n",
        "import time\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import ceil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read in Data"
      ],
      "metadata": {
        "id": "UVsJBk5HLLpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loads MNIST dataset for test and train sets\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data();\n",
        "\n",
        "# print shape of dataset\n",
        "print(\"x_train shape: {}; y_train shape: {}\".format(x_train.shape, y_train.shape))\n",
        "print(\"x_test shape: {}; y_test shape: {}\".format(x_test.shape, y_test.shape))\n",
        "\n",
        "# MNIST image preprocessing\n",
        "# flattens images\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2];\n",
        "x_test = x_test.reshape((x_test.shape[0], num_pixels)).astype('float32');\n",
        "x_train = x_train.reshape((x_train.shape[0], num_pixels)).astype('float32');\n",
        "\n",
        "# normalizes \n",
        "x_test = x_test/255;\n",
        "x_train = x_train/255;\n",
        "\n",
        "# one hot encoding\n",
        "y_test = np_utils.to_categorical(y_test);\n",
        "y_train = np_utils.to_categorical(y_train);\n",
        "\n",
        "# number of categories in MNIST\n",
        "num_classes = y_test.shape[1];"
      ],
      "metadata": {
        "id": "ficsMbGyb7-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9914835-0414-44a9-badc-33eb8fe64dc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28); y_train shape: (60000,)\n",
            "x_test shape: (10000, 28, 28); y_test shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set training hyperparameters\n",
        "\n",
        "learning_rate = 0.01\n",
        "weight_decay = 0.001\n",
        "batch_size = 256\n",
        "num_epochs = 100\n",
        "image_size = 72  # resize input images\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "\n",
        "# transformer layer size\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]\n",
        "transformer_layers = 8\n",
        "\n",
        "# size of dense layers of final classifier\n",
        "mlp_head_units = [2048, 1024]"
      ],
      "metadata": {
        "id": "vxPz9EZnLJld"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performer Variants"
      ],
      "metadata": {
        "id": "cErcw40YlgxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_perfs(x_train, y_train,x_test, y_test):\n",
        "  '''\n",
        "  Initializes the model, train with x_train and y_train\n",
        "  with relevant performer attention kernal activation;\n",
        "  Tests on x_test and y_test and displays run time and error\n",
        "  '''\n",
        "  #######################\n",
        "  ### ReLU ACTIVATION ###\n",
        "  #######################\n",
        "\n",
        "  a = time.time();\n",
        "\n",
        "  # initialize model\n",
        "  model = Sequential();\n",
        "\n",
        "  # set architecture configuration and parameters\n",
        "  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'));\n",
        "  model.add(Dense(num_classes, kernel_initializer='normal', activation='relu'));\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']);\n",
        "\n",
        "  # fit to training dataset\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=0);\n",
        "\n",
        "  b = time.time();\n",
        "\n",
        "  # evaluate model\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0);\n",
        "  print(\"ReLU error: %\", (100-scores[1]*100));\n",
        "  print(\"ReLU run time: \", b - a);\n",
        "\n",
        "  ##########################\n",
        "  ### SOFTMAX ACTIVATION ###\n",
        "  ##########################\n",
        "\n",
        "  a = time.time();\n",
        "\n",
        "  # initialize model\n",
        "  model = Sequential();\n",
        "\n",
        "  # set architecture configuration and parameters\n",
        "  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='softmax'));\n",
        "  model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'));\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']);\n",
        "\n",
        "  # fit to training dataset\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=0);\n",
        "\n",
        "  b = time.time();\n",
        "\n",
        "  # evaluate model\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0);\n",
        "  print(\"Softmax error: %\",(100-scores[1]*100));\n",
        "  print(\"Softmax run time: \", b - a);\n",
        "\n",
        "  ###############################\n",
        "  ### PERFORMER-X4 ACTIVATION ###\n",
        "  ###############################\n",
        "\n",
        "  # define custom activation function\n",
        "  def custom_activation(x):\n",
        "    # performer x4 activation\n",
        "    return tf.math.pow(x,4)\n",
        "\n",
        "  get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "  a = time.time();\n",
        "\n",
        "  # initialize model\n",
        "  model = Sequential();\n",
        "\n",
        "  # set architecture configuration and parameters\n",
        "  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation=\"custom_activation\"));\n",
        "  model.add(Dense(num_classes, kernel_initializer='normal', activation=\"custom_activation\"));\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']);\n",
        "\n",
        "  # fit to training dataset\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=0);\n",
        "\n",
        "  b = time.time();\n",
        "\n",
        "  # evaluate model\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0);\n",
        "  print(\"x^4 Error: %\",(100-scores[1]*100));\n",
        "  print(\"x^4 run time: \", b - a);\n",
        "\n",
        "  #################################\n",
        "  ### PERFORMER QUAD ACTIVATION ###\n",
        "  #################################\n",
        "\n",
        "  # define custom activation function\n",
        "  def custom_activation(x):\n",
        "    # performer quad activation\n",
        "    return tf.math.maximum(tf.math.pow(x,4),0)\n",
        "\n",
        "  get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "  a = time.time();\n",
        "\n",
        "  # initialize model \n",
        "  model = Sequential();\n",
        "\n",
        "  # set architecture configuration and parameters\n",
        "  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation=\"custom_activation\"));\n",
        "  model.add(Dense(num_classes, kernel_initializer='normal', activation=\"custom_activation\"));\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']);\n",
        "\n",
        "  # fit to training dataset\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=0);\n",
        "\n",
        "  b = time.time();\n",
        "\n",
        "  # evaluate model\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0);\n",
        "  print(\"Quad error: \", (100-scores[1]*100));\n",
        "  print(\"Quad run time: \", b - a);\n",
        "\n",
        "  ###############################\n",
        "  ### PERFORMER X2 ACTIVATION ###\n",
        "  ###############################\n",
        "\n",
        "  # define custom activation function\n",
        "  def custom_activation(x):\n",
        "    # performer x2 activation\n",
        "    return tf.math.pow(x,2)\n",
        "\n",
        "  get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "  a = time.time();\n",
        "\n",
        "  # initialize model\n",
        "  model = Sequential();\n",
        "\n",
        "  # set architecture configuration and parameters\n",
        "  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation=\"custom_activation\"));\n",
        "  model.add(Dense(num_classes, kernel_initializer='normal', activation=\"custom_activation\"));\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']);\n",
        "\n",
        "  # fit to training dataset\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=0);\n",
        "\n",
        "  b = time.time();\n",
        "\n",
        "  # model evaluation\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0);\n",
        "  print(\"x^2 error: %\", (100-scores[1]*100));\n",
        "  print(\"x^2 run time: \", b - a);\n",
        "\n",
        "  ####################################\n",
        "  ### PERFORMER RELU X2 ACTIVATION ###\n",
        "  ####################################\n",
        "\n",
        "  # define custom activation function\n",
        "  def custom_activation(x):\n",
        "    # performer relu x2 activation\n",
        "    return tf.math.maximum(tf.math.pow(x,2),0)\n",
        "\n",
        "  get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "  a = time.time();\n",
        "\n",
        "  # initialize model\n",
        "  model = Sequential();\n",
        "\n",
        "  # set architecture configuration and parameters\n",
        "  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation=\"custom_activation\"));\n",
        "  model.add(Dense(num_classes, kernel_initializer='normal', activation=\"custom_activation\"));\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']);\n",
        "\n",
        "  # fit to training dataset\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=0);\n",
        "\n",
        "  b = time.time();\n",
        "\n",
        "  # evaluate model\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0);\n",
        "  print(\"max(x^2,0) error: %\", (100-scores[1]*100));\n",
        "  print(\"max(x^2,0) run time: \", b - a);"
      ],
      "metadata": {
        "id": "nqo8awWJc-fX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run training on all performer variants\n",
        "run_perfs(x_train, y_train,x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRWKNKQ9f4Kv",
        "outputId": "d235834e-e2d1-4d92-d61b-452c0491977d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReLU error: % 90.20000025629997\n",
            "ReLU run time:  56.77838921546936\n",
            "Softmax error: % 6.099998950958252\n",
            "Softmax run time:  48.3295521736145\n",
            "x^4 Error: % 2.1000027656555176\n",
            "x^4 run time:  62.79771566390991\n",
            "Quad error:  3.4699976444244385\n",
            "Quad run time:  63.37994909286499\n",
            "x^2 error: % 3.1599998474121094\n",
            "x^2 run time:  46.91620850563049\n",
            "max(x^2,0) error: % 3.850001096725464\n",
            "max(x^2,0) run time:  48.58880925178528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation Studies"
      ],
      "metadata": {
        "id": "7jPbT6KYBolG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to sample \n",
        "def random_sample(sample_size, replacement):\n",
        "  '''\n",
        "  Load in MNIST data and generate random sample given a sample size\n",
        "  and whether to draw with or without replacement;\n",
        "  Process the image data (image flattening, normalization, one hot encoding)\n",
        "  '''\n",
        "\n",
        "  #loads MNIST dataset for test and train sets\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data();\n",
        "\n",
        "  # sample train sets\n",
        "  idx = np.random.choice(x_train.shape[0], sample_size, replace=replacement)\n",
        "  x_train = x_train[idx,:]\n",
        "  y_train = y_train[idx]\n",
        "\n",
        "  # sample test sets\n",
        "  idx = np.random.choice(x_test.shape[0], int(sample_size*(1/7)), replace=replacement)\n",
        "  x_test = x_test[idx,:]\n",
        "  y_test = y_test[idx]\n",
        "\n",
        "  # print shape of dataset after processing\n",
        "  print(\"x_train shape: {}; y_train shape: {}\".format(x_train.shape, y_train.shape))\n",
        "  print(\"x_test shape: {}; y_test shape: {}\".format(x_test.shape, y_test.shape))\n",
        "\n",
        "  # MNIST image preprocessing\n",
        "  # flattens images\n",
        "  num_pixels = x_train.shape[1] * x_train.shape[2];\n",
        "  x_test = x_test.reshape((x_test.shape[0], num_pixels)).astype('float32');\n",
        "  x_train = x_train.reshape((x_train.shape[0], num_pixels)).astype('float32');\n",
        "\n",
        "  # normalizes \n",
        "  x_test = x_test/255;\n",
        "  x_train = x_train/255;\n",
        "\n",
        "  # one hot encoding\n",
        "  y_test = np_utils.to_categorical(y_test);\n",
        "  y_train = np_utils.to_categorical(y_train);\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "pAz-DuCHYoH7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling without Replacement"
      ],
      "metadata": {
        "id": "v4R5HLxKaCTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10000 samples in training\n",
        "x_train, y_train, x_test, y_test = random_sample(10000, False)\n",
        "\n",
        "# number of categories in MNIST\n",
        "num_classes = y_test.shape[1];\n",
        "\n",
        "# run performer variants\n",
        "run_perfs(x_train, y_train,x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY4mzRt6TOHO",
        "outputId": "00184db6-77f5-4033-e376-05c143eeeaa5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (10000, 28, 28); y_train shape: (10000,)\n",
            "x_test shape: (1428, 28, 28); y_test shape: (1428,)\n",
            "ReLU error: % 89.14565816521645\n",
            "ReLU run time:  12.481255769729614\n",
            "Softmax error: % 8.473390340805054\n",
            "Softmax run time:  9.651816368103027\n",
            "x^4 Error: % 6.372547149658203\n",
            "x^4 run time:  10.890950441360474\n",
            "Quad error:  6.372547149658203\n",
            "Quad run time:  12.476388692855835\n",
            "x^2 error: % 6.372547149658203\n",
            "x^2 run time:  9.540419101715088\n",
            "max(x^2,0) error: % 6.092435121536255\n",
            "max(x^2,0) run time:  20.951552867889404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20000 samples in training\n",
        "x_train, y_train, x_test, y_test = random_sample(20000, False)\n",
        "\n",
        "# number of categories in MNIST\n",
        "num_classes = y_test.shape[1];\n",
        "\n",
        "# run performer variants\n",
        "run_perfs(x_train, y_train,x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t2AFGVfRQIe",
        "outputId": "5855e70f-80ff-4d8b-abbf-c91535caa751"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (20000, 28, 28); y_train shape: (20000,)\n",
            "x_test shape: (2857, 28, 28); y_test shape: (2857,)\n",
            "ReLU error: % 90.02450108528137\n",
            "ReLU run time:  15.686229228973389\n",
            "Softmax error: % 7.280361652374268\n",
            "Softmax run time:  16.897547960281372\n",
            "x^4 Error: % 3.6051809787750244\n",
            "x^4 run time:  19.826745748519897\n",
            "Quad error:  5.495274066925049\n",
            "Quad run time:  20.738535165786743\n",
            "x^2 error: % 5.1452577114105225\n",
            "x^2 run time:  20.95934224128723\n",
            "max(x^2,0) error: % 4.2002081871032715\n",
            "max(x^2,0) run time:  16.72758984565735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 50000 samples in training\n",
        "x_train, y_train, x_test, y_test = random_sample(50000, False)\n",
        "\n",
        "# number of categories in MNIST\n",
        "num_classes = y_test.shape[1];\n",
        "\n",
        "# run performer variants\n",
        "run_perfs(x_train, y_train,x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEeDa575RSq5",
        "outputId": "e4c64e0a-833f-49c6-eca2-c2f5cd6f4a4e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 28, 28); y_train shape: (50000,)\n",
            "x_test shape: (7142, 28, 28); y_test shape: (7142,)\n",
            "ReLU error: % 90.21282568573952\n",
            "ReLU run time:  45.36798691749573\n",
            "Softmax error: % 6.594789028167725\n",
            "Softmax run time:  41.87660479545593\n",
            "x^4 Error: % 2.3942887783050537\n",
            "x^4 run time:  47.53387761116028\n",
            "Quad error:  2.5623083114624023\n",
            "Quad run time:  50.792929887771606\n",
            "x^2 error: % 5.586671829223633\n",
            "x^2 run time:  38.026211977005005\n",
            "max(x^2,0) error: % 10.627275705337524\n",
            "max(x^2,0) run time:  41.602829456329346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling with Replacement"
      ],
      "metadata": {
        "id": "68Jm6rGAbMiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10000 samples in training\n",
        "x_train, y_train, x_test, y_test = random_sample(10000, True)\n",
        "\n",
        "# number of categories in MNIST\n",
        "num_classes = y_test.shape[1];\n",
        "\n",
        "# run performer variants\n",
        "run_perfs(x_train, y_train,x_test, y_test)"
      ],
      "metadata": {
        "id": "XHNnKPlY7-Xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf4cb71-7330-4cce-af73-83ec58202848"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (10000, 28, 28); y_train shape: (10000,)\n",
            "x_test shape: (1428, 28, 28); y_test shape: (1428,)\n",
            "ReLU error: % 88.51540610194206\n",
            "ReLU run time:  9.160441160202026\n",
            "Softmax error: % 14.075630903244019\n",
            "Softmax run time:  8.8079833984375\n",
            "x^4 Error: % 3.7114858627319336\n",
            "x^4 run time:  10.35050344467163\n",
            "Quad error:  7.0728302001953125\n",
            "Quad run time:  10.860066652297974\n",
            "x^2 error: % 7.422971725463867\n",
            "x^2 run time:  9.58069396018982\n",
            "max(x^2,0) error: % 8.683472871780396\n",
            "max(x^2,0) run time:  9.46939730644226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20000 samples in training\n",
        "x_train, y_train, x_test, y_test = random_sample(20000, True)\n",
        "\n",
        "# number of categories in MNIST\n",
        "num_classes = y_test.shape[1];\n",
        "\n",
        "# run performer variants\n",
        "run_perfs(x_train, y_train,x_test, y_test)"
      ],
      "metadata": {
        "id": "BnsNwhsUjHp7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5eb2c2c-9e07-4669-8bd2-b5bb4c6bfb63"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (20000, 28, 28); y_train shape: (20000,)\n",
            "x_test shape: (2857, 28, 28); y_test shape: (2857,)\n",
            "ReLU error: % 90.26951342821121\n",
            "ReLU run time:  16.256171703338623\n",
            "Softmax error: % 7.4553728103637695\n",
            "Softmax run time:  20.95085120201111\n",
            "x^4 Error: % 5.635279417037964\n",
            "x^4 run time:  20.9736111164093\n",
            "Quad error:  3.3601701259613037\n",
            "Quad run time:  20.446016788482666\n",
            "x^2 error: % 9.100455045700073\n",
            "x^2 run time:  20.949095249176025\n",
            "max(x^2,0) error: % 8.225411176681519\n",
            "max(x^2,0) run time:  16.69939422607422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 50000 samples in training\n",
        "x_train, y_train, x_test, y_test = random_sample(50000, True)\n",
        "\n",
        "# number of categories in MNIST\n",
        "num_classes = y_test.shape[1];\n",
        "\n",
        "# run performer variants\n",
        "run_perfs(x_train, y_train,x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSnwMfV3bTKk",
        "outputId": "9f8cf6f4-d9e6-4acb-cba2-ceccb862c5c9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 28, 28); y_train shape: (50000,)\n",
            "x_test shape: (7142, 28, 28); y_test shape: (7142,)\n",
            "ReLU error: % 90.07280841469765\n",
            "ReLU run time:  38.50339365005493\n",
            "Softmax error: % 6.888824701309204\n",
            "Softmax run time:  43.930743932724\n",
            "x^4 Error: % 3.136378526687622\n",
            "x^4 run time:  48.23574495315552\n",
            "Quad error:  3.962475061416626\n",
            "Quad run time:  82.41865348815918\n",
            "x^2 error: % 4.158496856689453\n",
            "x^2 run time:  40.70253872871399\n",
            "max(x^2,0) error: % 4.802578687667847\n",
            "max(x^2,0) run time:  40.54644560813904\n"
          ]
        }
      ]
    }
  ]
}